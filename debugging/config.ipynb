{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use jupyter in vscode(docker), you need install jupyter & python extension on vscode\n",
    "# and run 'conda install -n base ipykernel --update-deps --force-reinstall' in terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ws/HanhwaIRChallenge/MMdet-ObjectDetection/debugging/../projects/configs/baseline/baseline.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "config_path = os.getcwd() + '/../projects/configs/baseline/baseline.py'\n",
    "print(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from mmcv import Config, DictAction\n",
    "\n",
    "cfg = Config.fromfile(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config (path: /ws/HanhwaIRChallenge/MMdet-ObjectDetection/debugging/../projects/configs/baseline/baseline.py): {'dataset_type': 'HanhwaIRDataset', 'data_root': 'data/IRData/', 'img_norm_cfg': None, 'train_pipeline': [{'type': 'LoadImageFromFile', 'color_type': 'grayscale'}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels']}], 'test_pipeline': [{'type': 'LoadImageFromFile', 'color_type': 'grayscale'}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels']}], 'data': {'samples_per_gpu': 4, 'workers_per_gpu': 4, 'train': {'type': 'HanhwaIRDataset', 'ann_file': 'data/IRData/annotations/train.json', 'img_prefix': 'data/IRData/train/', 'pipeline': [{'type': 'LoadImageFromFile', 'color_type': 'grayscale'}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels']}], 'data_root': 'data/IRData/', 'classes': ['person', 'car', 'truck', 'bus', 'bicycle', 'bike', 'extra_vehicle', 'dog']}, 'val': {'type': 'HanhwaIRDataset', 'ann_file': 'data/IRData/annotations/val.json', 'img_prefix': 'data/IRData/val/', 'pipeline': [{'type': 'LoadImageFromFile', 'color_type': 'grayscale'}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels']}], 'data_root': 'data/IRData/', 'classes': ['person', 'car', 'truck', 'bus', 'bicycle', 'bike', 'extra_vehicle', 'dog']}, 'test': {'type': 'HanhwaIRDataset', 'ann_file': 'data/IRData/annotations/val.json', 'img_prefix': 'data/IRData/val/', 'pipeline': [{'type': 'LoadImageFromFile', 'color_type': 'grayscale'}, {'type': 'LoadAnnotations', 'with_bbox': True}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels']}], 'data_root': 'data/IRData/', 'classes': ['person', 'car', 'truck', 'bus', 'bicycle', 'bike', 'extra_vehicle', 'dog']}}, 'evaluation': {'interval': 1, 'metric': 'bbox'}, 'project': 'baseline', 'project_name': 'baseline', 'wandb_entity': 'holyjoon', 'backbone_norm_cfg': {'type': 'LN', 'requires_grad': True}, 'plugin': True, 'plugin_dir': 'projects/mmdet_plugin/', 'log_config': {'interval': 50, 'hooks': [{'type': 'TextLoggerHook'}, {'type': 'TesnroboardLoggerHook'}, {'type': 'MMDetWandbHook', 'by_epoch': False, 'init_kwargs': {'entity': 'holyjoon', 'project': 'baseline'}}]}, 'class_names': ['person', 'car', 'truck', 'bus', 'bicycle', 'bike', 'extra_vehicle', 'dog'], 'num_gpus': 1, 'batch_size': 4, 'num_epochs': 20, 'runner': {'type': 'EpochBasedRunner', 'max_epoch': 20}, 'lr_config': {'policy': 'step', 'warmup': 'linear', 'warmup_ratio': 0.001, 'step': [8, 11]}, 'optimizer': {'type': 'AdamW', 'lr': 0.0001, 'paramwise_cfg': {'custom_keys': {'backbone': {'lr_mult': 0.25}}}, 'weight_decay': 0.01}, 'load_from': None, 'resume_from': None}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.get('custom_imports', None) == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(cfg, 'plugin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "projects.mmdet_plugin\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "if cfg.plugin:\n",
    "    import importlib\n",
    "    if hasattr(cfg, 'plugin_dir'):\n",
    "        plugin_dir = cfg.plugin_dir\n",
    "        _module_dir = os.path.dirname(plugin_dir)\n",
    "        _module_dir = _module_dir.split('/')\n",
    "        _module_path = _module_dir[0]\n",
    "\n",
    "        for m in _module_dir[1:]:\n",
    "            _module_path = _module_path + '.' + m\n",
    "        print(_module_path)\n",
    "        plg_lib = importlib.import_module(_module_path)\n",
    "    else:\n",
    "        # import dir is the dirpath for the config file\n",
    "        _module_dir = os.path.dirname(args.config)\n",
    "        _module_dir = _module_dir.split('/')\n",
    "        _module_path = _module_dir[0]\n",
    "        for m in _module_dir[1:]:\n",
    "            _module_path = _module_path + '.' + m\n",
    "        print(_module_path)\n",
    "        plg_lib = importlib.import_module(_module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.datasets import build_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "HanhwaIRDataset: [Errno 2] No such file or directory: 'data/IRData/data/IRData/annotations/train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/mmcv/utils/registry.py:69\u001b[0m, in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# Normal TypeError does not print class name.\u001b[39;00m\n",
      "File \u001b[0;32m/ws/HanhwaIRChallenge/MMdet-ObjectDetection/mmdetection/mmdet/datasets/custom.py:97\u001b[0m, in \u001b[0;36mCustomDataset.__init__\u001b[0;34m(self, ann_file, pipeline, classes, data_root, img_prefix, seg_prefix, seg_suffix, proposal_file, test_mode, filter_empty_gt, file_client_args)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_client\u001b[38;5;241m.\u001b[39mget_local_path(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mann_file) \u001b[38;5;28;01mas\u001b[39;00m local_path:\n\u001b[0;32m---> 97\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_annotations\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocal_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/ws/HanhwaIRChallenge/MMdet-ObjectDetection/debugging/../projects/mmdet_plugin/datasets/hanhwa_dataset.py:37\u001b[0m, in \u001b[0;36mHanhwaIRDataset.load_annotations\u001b[0;34m(self, ann_file)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"_summary_\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124;03m    ann_file (_type_): _description_\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoco \u001b[38;5;241m=\u001b[39m \u001b[43mCOCO\u001b[49m\u001b[43m(\u001b[49m\u001b[43mann_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcat_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoco\u001b[38;5;241m.\u001b[39mgetCatIds() \u001b[38;5;66;03m#get All Category Ids out : 0,1,2,...,7\u001b[39;00m\n",
      "File \u001b[0;32m/ws/HanhwaIRChallenge/MMdet-ObjectDetection/mmdetection/mmdet/datasets/api_wrappers/coco_api.py:23\u001b[0m, in \u001b[0;36mCOCO.__init__\u001b[0;34m(self, annotation_file)\u001b[0m\n\u001b[1;32m     20\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     21\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmmpycocotools is deprecated. Please install official pycocotools by \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpip install pycocotools\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m)\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mannotation_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotation_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimg_ann_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimgToAnns\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/pycocotools/coco.py:81\u001b[0m, in \u001b[0;36mCOCO.__init__\u001b[0;34m(self, annotation_file)\u001b[0m\n\u001b[1;32m     80\u001b[0m tic \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mannotation_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     82\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/IRData/data/IRData/annotations/train.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m datasets \u001b[38;5;241m=\u001b[39m [\u001b[43mbuild_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[0;32m/ws/HanhwaIRChallenge/MMdet-ObjectDetection/mmdetection/mmdet/datasets/builder.py:82\u001b[0m, in \u001b[0;36mbuild_dataset\u001b[0;34m(cfg, default_args)\u001b[0m\n\u001b[1;32m     80\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m _concat_dataset(cfg, default_args)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 82\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_from_cfg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATASETS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/mmcv/utils/registry.py:72\u001b[0m, in \u001b[0;36mbuild_from_cfg\u001b[0;34m(cfg, registry, default_args)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj_cls(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# Normal TypeError does not print class name.\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(e)(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobj_cls\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: HanhwaIRDataset: [Errno 2] No such file or directory: 'data/IRData/data/IRData/annotations/train.json'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
